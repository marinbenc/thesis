%----------------------------------------------------------------------------------------
%  ABSTRACT PAGE
%----------------------------------------------------------------------------------------
\MakeShortVerb{\|}

\begin{abstract}
 \addchaptertocentry{\abstractname} % Add the abstract to the table of contents

Medical image segmentation plays a pivotal role in various medical applications from surgical planning to diagnosis and research. This process heavily relies on neural networks for accurate segmentation across different imaging modalities such as CT, MRI, microscopy dermatoscopy, and others. However, the effectiveness of these models is significantly influenced by the availability and quality of training data, which is often challenging to acquire due to the high time and financial cost of image acquisition, invasiveness of some imaging procedures, large file sizes, and regulatory challenges surrounding medical imaging.

The labor-intensive and expert-driven nature of medical image annotation further compounds these challenges, making the assembly of large, high-quality datasets for neural network training particularly difficult. This scarcity of data necessitates the development of data-efficient segmentation methods that can deliver reliable results with limited training samples.

From the fields of statistics and learning theory, we theoretically establish that as medical image segmentation tasks grow in complexity, they necessitate neural networks with an increasing number of parameters for effective segmentation. This requirement for more parameters, in turn, demands larger sample sizes to avoid overfitting. In medical imaging, however, there is a lack of datasets with large sample sizes. In this thesis, we present an overview of medical image segmentation methods and existing strategies for improving their data efficiency.

We propose various new methods that simplify the segmentation task, allowing neural networks to function with fewer parameters and, by extension, smaller datasets. Our methods center on transforming the segmentation boundary into a representation that can modelled with fewer parameters. We do so by leveraging domain knowledge and traditional image-processing techniques to identify beneficial image transformations. The parameters of the image transformations are dynamically selected for each image using neural networks, breaking down the segmentation task into two more manageable stages: an initial rough localization of the target object followed by the segmentation of a simplified representation of the image.

The effectiveness of these methods is validated across various medical imaging modalities, including CT scans, microscopy, dermatoscopy, and colonoscopy, showing not only enhanced data efficiency but also achieving leading-edge results in certain cases. The techniques introduced are versatile, suitable for a broad spectrum of medical imaging fields, and can serve as general preprocessing steps for any convolutional neural network-based segmentation architecture.

In addressing the challenge of data efficiency in medical image segmentation, this thesis introduces the following original scientific contributions:

\begin{enumerate}
	\item \textbf{A new biomedical image segmentation method based on polar transform preprocessing with a learned center point.} We introduce a novel preprocessing technique for medical images, particularly those with elliptically shaped objects. By applying a polar transform, we simplify circular decision boundaries into linear ones, making segmentation more straightforward. A neural network is developed to identify the optimal center points for segmentation, enhancing performance and allowing the use of less complex networks.
	\item \textbf{An improved method of reducing the input image size in neural networks using salient image crops.} Building on the polar transform insights, we propose a model-driven cropping technique to minimize neural network input sizes without sacrificing fine details. By localizing the target object in a downsampled image and extracting high-resolution crops, we maintain precise segmentation with smaller network input sizes. We show that this improves data efficiency as model complexity increases with image size.
	\item \textbf{A new neural network architecture for high-resolution image segmentation that combines object detection in low-resolution images and segmentation in high-resolution images.} We extend our preprocessing methods to create an end-to-end trainable network that combines low-resolution object detection with high-resolution image segmentation. We allow network convergence in two key ways. First, we use a shared architecture between the rough and fine segmentation subnetworks which allows transfer learning. Secondly, we pass information from one subnetwork to the other, to ensure gradient flow. We show that training this end-to-end network increases the robustness of both the rough and fine segmentation stages.
	\item \textbf{A new method of embedding depth information in two-dimensional convolutional neural network input data.} Acknowledging the data efficiency limitations of 3D networks for volumetric data like CT scans, we develop a method to embed depth information into 2D slices by adding a normalized z-coordinate channel to each slice. We show that this allows effective segmentation of CT images with slice-based 2D networks.
\end{enumerate}

Each of the presented methods can be used as a general preprocessing step independent of the underlying convolutional neural network architecture. These contributions demonstrate the potential for generally simplifying medical image segmentation tasks and improving data efficiency across various medical imaging modalities and tasks.

The research presented in this thesis has resulted in the publication of four research papers in scientific journals (all as first author) and four papers presented at internal scientific conferences (of which three as first author). 

\end{abstract}