\babel@toc {english}{}\relax 
\contentsline {chapter}{Acknowledgements}{III}{section*.4}%
\contentsline {chapter}{Abstract}{IV}{chapter*.5}%
\contentsline {chapter}{Samenvatting}{VI}{chapter*.10}%
\contentsline {chapter}{Sa≈æetak}{VIII}{chapter*.15}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.21}%
\contentsline {section}{\numberline {1.1}Contributions}{2}{section.22}%
\contentsline {subsubsection}{A new biomedical image segmentation method based on polar transform preprocessing with a learned center point.}{2}{section*.23}%
\contentsline {subsubsection}{An improved method of reducing the input image size in neural networks using salient image crops.}{2}{section*.24}%
\contentsline {subsubsection}{A new neural network architecture for high-resolution image segmentation that combines object detection in low-resolution images and segmentation in high-resolution images.}{3}{section*.25}%
\contentsline {subsubsection}{A new method of embedding depth information in two-dimensional convolutional neural network input data.}{3}{section*.27}%
\contentsline {section}{\numberline {1.2}List of Publications}{3}{section.28}%
\contentsline {subsection}{\numberline {1.2.1}Publications in Scientific Journals}{3}{subsection.29}%
\contentsline {subsection}{\numberline {1.2.2}Publications in Scientific Conferences}{3}{subsection.30}%
\contentsline {section}{\numberline {1.3}Organization of the Thesis}{4}{section.31}%
\contentsline {section}{References}{5}{section*.32}%
\contentsline {chapter}{\numberline {2}Neural Network-Based Segmentation of Biomedical Images}{7}{chapter.33}%
\contentsline {section}{\numberline {2.1}Common Types of Biomedical Images}{7}{section.34}%
\contentsline {subsection}{\numberline {2.1.1}3D Modalities}{7}{subsection.35}%
\contentsline {subsubsection}{Computed Tomography (CT)}{8}{section*.36}%
\contentsline {subsubsection}{Magnetic Resonance Imaging (MRI)}{9}{section*.41}%
\contentsline {subsection}{\numberline {2.1.2}2D Modalities}{11}{subsection.46}%
\contentsline {subsubsection}{X-ray imaging}{11}{section*.47}%
\contentsline {subsubsection}{Dermatological images (clinical and dermatoscopic)}{11}{section*.48}%
\contentsline {subsubsection}{Microscopy}{12}{section*.49}%
\contentsline {section}{\numberline {2.2}Image Segmentation: From Images to Segmentation Maps}{12}{section.50}%
\contentsline {subsection}{\numberline {2.2.1}Traditional Image Processing Methods}{13}{subsection.52}%
\contentsline {subsubsection}{Image Thresholding}{13}{section*.53}%
\contentsline {subsubsection}{Region Growing Techniques}{14}{section*.54}%
\contentsline {subsubsection}{Active Contours or Snakes}{14}{section*.56}%
\contentsline {subsubsection}{Atlas-Based Segmentation}{15}{section*.58}%
\contentsline {subsection}{\numberline {2.2.2}Machine Learning}{15}{subsection.60}%
\contentsline {section}{\numberline {2.3}Deep Learning-Based Segmentation Methods}{17}{section.63}%
\contentsline {subsection}{\numberline {2.3.1}Neural Network Training, Validation and Testing}{18}{subsection.68}%
\contentsline {subsection}{\numberline {2.3.2}Encoders and Decoders}{19}{subsection.69}%
\contentsline {subsection}{\numberline {2.3.3}Convolutional Neural Networks}{20}{subsection.71}%
\contentsline {subsubsection}{Convolution}{20}{section*.72}%
\contentsline {subsubsection}{Convolutional Layers}{22}{section*.77}%
\contentsline {subsubsection}{Pooling Layers}{23}{section*.79}%
\contentsline {section}{\numberline {2.4}CNN Architectures for Medical Image Segmentation}{24}{section.81}%
\contentsline {subsection}{\numberline {2.4.1}Fully Convolutional Network (FCN)}{24}{subsection.82}%
\contentsline {subsection}{\numberline {2.4.2}U-Net and Its Variants}{25}{subsection.84}%
\contentsline {subsubsection}{nnU-Net}{26}{section*.86}%
\contentsline {subsubsection}{U-Net++}{27}{section*.88}%
\contentsline {subsection}{\numberline {2.4.3}Mask R-CNN}{28}{subsection.90}%
\contentsline {subsection}{\numberline {2.4.4}Other Notable Segmentation CNNs}{29}{subsection.92}%
\contentsline {section}{\numberline {2.5}Fully Connected Transformers for Medical Image Segmentation}{30}{section.93}%
\contentsline {subsection}{\numberline {2.5.1}Attention}{30}{subsection.94}%
\contentsline {subsection}{\numberline {2.5.2}Positional Encoding}{31}{subsection.100}%
\contentsline {subsection}{\numberline {2.5.3}Adapting Transformers to Image Segmentation}{32}{subsection.102}%
\contentsline {section}{References}{34}{section*.104}%
\contentsline {chapter}{\numberline {3}Data Efficiency in Neural Network-Based Image Segmentation}{37}{chapter.105}%
\contentsline {section}{\numberline {3.1}Transfer Learning}{40}{section.116}%
\contentsline {subsection}{\numberline {3.1.1}Simple Transfer Learning}{40}{subsection.117}%
\contentsline {subsection}{\numberline {3.1.2}Domain Adaptation}{41}{subsection.119}%
\contentsline {subsection}{\numberline {3.1.3}Semi-Supervised and Self-Supervised Learning}{42}{subsection.121}%
\contentsline {section}{\numberline {3.2}Synthetic Data}{43}{section.123}%
\contentsline {section}{\numberline {3.3}Regularization}{43}{section.124}%
\contentsline {section}{\numberline {3.4}Conclusion}{44}{section.127}%
\contentsline {section}{References}{45}{section*.128}%
\contentsline {chapter}{\numberline {4}Data Efficiency via Model-Driven Preprocessing}{47}{chapter.129}%
\contentsline {section}{\numberline {4.1}Motivation: Using The Polar Transform for Preprocessing}{47}{section.130}%
\contentsline {section}{\numberline {4.2}Model-driven Preprocessing}{49}{section.136}%
\contentsline {subsection}{\numberline {4.2.1}Training Model-Driven Preprocessing Networks}{51}{subsection.141}%
\contentsline {subsubsection}{Training the Transformation Parameter Predictor}{51}{section*.142}%
\contentsline {subsubsection}{Training the Segmentation Network}{52}{section*.144}%
\contentsline {subsubsection}{Transfer Learning}{52}{section*.146}%
\contentsline {section}{\numberline {4.3}Model-Driven Polar Transform Using Centerpoint Prediction}{53}{section.150}%
\contentsline {subsection}{\numberline {4.3.1}Background and Related Work}{53}{subsection.151}%
\contentsline {subsubsection}{Previous work using the polar transform for medical image processing}{54}{section*.154}%
\contentsline {subsection}{\numberline {4.3.2}Methodology}{55}{subsection.155}%
\contentsline {subsection}{\numberline {4.3.3}Centerpoint prediction}{55}{subsection.158}%
\contentsline {subsubsection}{(A) Training the same neural network on cartesian and polar images}{55}{section*.159}%
\contentsline {subsubsection}{(B) Training a centerpoint predictor}{56}{section*.161}%
\contentsline {subsection}{\numberline {4.3.4}Experiments}{58}{subsection.164}%
\contentsline {subsubsection}{Datasets description}{58}{section*.169}%
\contentsline {subsubsection}{Implementation details}{60}{section*.175}%
\contentsline {subsection}{\numberline {4.3.5}Results and Discussion}{60}{subsection.177}%
\contentsline {subsubsection}{Discussion}{64}{section*.184}%
\contentsline {section}{\numberline {4.4}Supporting Multiple Transformations of an Image}{66}{section.191}%
\contentsline {section}{\numberline {4.5}Model-Driven Preprocessing using Multiple Transformations for Aorta Segmentation}{68}{section.198}%
\contentsline {subsection}{\numberline {4.5.1}Methodology}{68}{subsection.199}%
\contentsline {subsubsection}{Data Description and Preprocessing}{69}{section*.202}%
\contentsline {subsection}{\numberline {4.5.2}Results and Discussion}{70}{subsection.203}%
\contentsline {section}{\numberline {4.6}Conclusion}{73}{section.208}%
\contentsline {section}{References}{74}{section*.209}%
\contentsline {chapter}{\numberline {5}Reducing Model Input Sizes with Model-Driven Crops}{77}{chapter.210}%
\contentsline {section}{\numberline {5.1}Model-Driven Image Cropping}{78}{section.213}%
\contentsline {subsubsection}{Cropping}{79}{section*.218}%
\contentsline {subsubsection}{Fine Segmentation and Fusion}{81}{section*.219}%
\contentsline {subsubsection}{Training the Fine Segmentation Network}{81}{section*.220}%
\contentsline {subsection}{\numberline {5.1.1}Related work}{81}{subsection.221}%
\contentsline {subsubsection}{Detect-then-segment}{81}{section*.222}%
\contentsline {subsubsection}{Coarse-to-fine Segmentation}{82}{section*.223}%
\contentsline {subsubsection}{Non-uniform Downsampling}{82}{section*.224}%
\contentsline {subsubsection}{Other Approaches to Reducing Input Resolution}{83}{section*.225}%
\contentsline {subsection}{\numberline {5.1.2}Results}{83}{subsection.226}%
\contentsline {subsubsection}{Datasets}{84}{section*.228}%
\contentsline {subsubsection}{Quantitative Assessment}{84}{section*.229}%
\contentsline {subsubsection}{Qualitative Assessment}{87}{section*.234}%
\contentsline {subsubsection}{Computational Performance Characteristics}{90}{section*.238}%
\contentsline {subsection}{\numberline {5.1.3}Discussion}{91}{subsection.241}%
\contentsline {section}{\numberline {5.2}An End-to-End Extension of Model-Driven Image Cropping}{92}{section.242}%
\contentsline {subsection}{\numberline {5.2.1}End-to-end Network Architecture and Training}{92}{subsection.243}%
\contentsline {subsection}{\numberline {5.2.2}Experiments in Clinical Dermatological Image Segmentation}{93}{subsection.245}%
\contentsline {subsubsection}{Results and Discussion}{93}{section*.246}%
\contentsline {section}{\numberline {5.3}Conclusion}{97}{section.250}%
\contentsline {section}{References}{98}{section*.252}%
\contentsline {chapter}{\numberline {6}Adding Depth Information to 2D U-Nets for CT Segmentation}{101}{chapter.253}%
\contentsline {section}{\numberline {6.1}Epicardial Adipose Tissue Segmentation}{102}{section.255}%
\contentsline {section}{\numberline {6.2}Related Work}{102}{section.256}%
\contentsline {section}{\numberline {6.3}Dataset Description}{103}{section.257}%
\contentsline {section}{\numberline {6.4}Methodology}{103}{section.259}%
\contentsline {subsection}{\numberline {6.4.1}Data Preprocessing}{104}{subsection.262}%
\contentsline {subsection}{\numberline {6.4.2}Model Training}{105}{subsection.264}%
\contentsline {section}{\numberline {6.5}Experiments and Results}{105}{section.265}%
\contentsline {subsection}{\numberline {6.5.1}Results}{106}{subsection.266}%
\contentsline {section}{\numberline {6.6}Conclusion}{108}{section.271}%
\contentsline {section}{References}{109}{section*.272}%
\contentsline {chapter}{\numberline {7}Conclusion}{111}{chapter.273}%
\contentsline {chapter}{\numberline {8}Curriculum Vitae}{113}{chapter.274}%
