\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Reducing Model Input Sizes with Model-Driven Crops}{79}{chapter.208}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:reducing-input-size}{{5}{79}{Reducing Model Input Sizes with Model-Driven Crops}{chapter.208}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Model-Driven Image Cropping}{80}{section.211}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A visual summary of our approach. (1) An image is uniformly downsampled from its original resolution. (2) A rough segmentation is predicted by a neural network, and the bounding box of each connected component is calculated. (3) The bounding boxes are scaled to the original image space and crops of the input image are taken in the original resolution and scaled to a common input size. (4) Each crop is segmented separately by a second neural network specifically trained on cropped images. These crops are fused to form a final segmentation in the original high resolution. \blx@tocontentsinit {5}\cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }}{80}{figure.caption.212}\protected@file@percent }
\newlabel{fig:summary}{{5.1}{80}{A visual summary of our approach. (1) An image is uniformly downsampled from its original resolution. (2) A rough segmentation is predicted by a neural network, and the bounding box of each connected component is calculated. (3) The bounding boxes are scaled to the original image space and crops of the input image are taken in the original resolution and scaled to a common input size. (4) Each crop is segmented separately by a second neural network specifically trained on cropped images. These crops are fused to form a final segmentation in the original high resolution. \cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }{figure.caption.212}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cropping}{81}{section*.216}\protected@file@percent }
\newlabel{cropping}{{5.1}{81}{Cropping}{section*.216}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Inference algorithm for one input image\relax }}{82}{algorithm.215}\protected@file@percent }
\newlabel{alg:crop}{{1}{82}{Inference algorithm for one input image\relax }{algorithm.215}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fine Segmentation and Fusion}{83}{section*.217}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training the Fine Segmentation Network}{83}{section*.218}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Related work}{83}{subsection.219}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Detect-then-segment}{83}{section*.220}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Coarse-to-fine Segmentation}{84}{section*.221}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Non-uniform Downsampling}{84}{section*.222}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Other Approaches to Reducing Input Resolution}{85}{section*.223}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Results}{85}{subsection.224}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Datasets}{85}{section*.226}\protected@file@percent }
\newlabel{datasets}{{5.1.2}{85}{Datasets}{section*.226}{}}
\newlabel{tab:hyperparams}{{5.1}{86}{The hyper-parameters used for each of the models in our experiments.\relax }{table.225}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces The hyper-parameters used for each of the models in our experiments.\relax }}{86}{table.225}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Quantitative Assessment}{86}{section*.227}\protected@file@percent }
\newlabel{tab:seg-then-seg-results}{{5.2}{87}{The results of our approach using U-Net as the underlying architecture.\relax }{table.228}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces The results of our approach using U-Net as the underlying architecture.\relax }}{87}{table.228}\protected@file@percent }
\newlabel{tab:other-sota}{{5.3}{88}{A comparison of the Dice Score Coefficients of our approach using other underlying architectures at 4x and 2x downscaled images.\relax }{table.229}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces A comparison of the Dice Score Coefficients of our approach using other underlying architectures at 4x and 2x downscaled images.\relax }}{88}{table.229}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The relationship between input dimensions and the mean Dice Score Coefficient (DSC) and recall for different datasets. The points are measured values from our experiments.\relax }}{88}{figure.caption.230}\protected@file@percent }
\newlabel{fig:dsc-vs-size}{{5.2}{88}{The relationship between input dimensions and the mean Dice Score Coefficient (DSC) and recall for different datasets. The points are measured values from our experiments.\relax }{figure.caption.230}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Violin plots of Dice Score Coefficients of our approach compared to the baseline models at various input dimensions. The dashed lines represent quartiles of the distributions.\relax }}{89}{figure.caption.231}\protected@file@percent }
\newlabel{fig:box-plots}{{5.3}{89}{Violin plots of Dice Score Coefficients of our approach compared to the baseline models at various input dimensions. The dashed lines represent quartiles of the distributions.\relax }{figure.caption.231}{}}
\@writefile{toc}{\contentsline {subsubsection}{Qualitative Assessment}{90}{section*.232}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Example outputs from the models for the cells dataset at various input sizes. \blx@tocontentsinit {5}\cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }}{90}{figure.caption.233}\protected@file@percent }
\newlabel{fig:examples-cells}{{5.4}{90}{Example outputs from the models for the cells dataset at various input sizes. \cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }{figure.caption.233}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Example outputs from the models for the polyp dataset at various input sizes. \blx@tocontentsinit {5}\cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }}{91}{figure.caption.234}\protected@file@percent }
\newlabel{fig:examples-polyp}{{5.5}{91}{Example outputs from the models for the polyp dataset at various input sizes. \cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }{figure.caption.234}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Example outputs from the models for the aorta dataset at various input sizes. \blx@tocontentsinit {5}\cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }}{91}{figure.caption.235}\protected@file@percent }
\newlabel{fig:examples-aa}{{5.6}{91}{Example outputs from the models for the aorta dataset at various input sizes. \cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }{figure.caption.235}{}}
\@writefile{toc}{\contentsline {subsubsection}{Computational Performance Characteristics}{91}{section*.236}\protected@file@percent }
\newlabel{tab:performance}{{5.4}{92}{Performance characteristics of our approach compared to the baseline model with similar mean test Dice Score Coefficients.\relax }{table.237}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Performance characteristics of our approach compared to the baseline model with similar mean test Dice Score Coefficients.\relax }}{92}{table.237}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Mean per-input inference time across different input sizes for the U-Net-based models. \blx@tocontentsinit {5}\cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }}{92}{figure.caption.238}\protected@file@percent }
\newlabel{fig:inf-time}{{5.7}{92}{Mean per-input inference time across different input sizes for the U-Net-based models. \cite {bencevicSegmentthenSegmentContextPreservingCropBased2023a}\relax }{figure.caption.238}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}An End-to-End Extension of Model-Driven Image Cropping}{93}{section.239}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}End-to-end Network Architecture and Training}{93}{subsection.240}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Experiments in Clinical Dermatological Image Segmentation}{94}{subsection.242}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces An illustration of the end-to-end model-driven cropping architecture, comprising two interconnected modules: a coarse and a fine segmentation module, linked via a cropping layer. Both modules are designed to handle images of small, fixed input sizes. The first module processes a downscaled version of the input image. Its segmentation output determines the region of interest in the high-resolution image, which, along with the cropped initial segmentation, is fed into the fine segmentation module. Before being fine-tuned together, both networks are pre-trained as standard segmentation networks.\relax }}{94}{figure.caption.241}\protected@file@percent }
\newlabel{fig:e2e-diagram}{{5.8}{94}{An illustration of the end-to-end model-driven cropping architecture, comprising two interconnected modules: a coarse and a fine segmentation module, linked via a cropping layer. Both modules are designed to handle images of small, fixed input sizes. The first module processes a downscaled version of the input image. Its segmentation output determines the region of interest in the high-resolution image, which, along with the cropped initial segmentation, is fed into the fine segmentation module. Before being fine-tuned together, both networks are pre-trained as standard segmentation networks.\relax }{figure.caption.241}{}}
\@writefile{toc}{\contentsline {subsubsection}{Results and Discussion}{95}{section*.243}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Randomly chosen examples of out-of-sample segmentation results. The columns, from left to right, show the input image with the ground truth segmentation mask, the final output segmentation mask of our approach, the rough segmentation of our approach, and the output of a baseline U-Net model. The images are zoomed in on the lesion region.\relax }}{96}{figure.caption.244}\protected@file@percent }
\newlabel{fig:visual}{{5.9}{96}{Randomly chosen examples of out-of-sample segmentation results. The columns, from left to right, show the input image with the ground truth segmentation mask, the final output segmentation mask of our approach, the rough segmentation of our approach, and the output of a baseline U-Net model. The images are zoomed in on the lesion region.\relax }{figure.caption.244}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Results of our approach and the baseline model in terms of the Dice Coefficient (DSC) as well as the thresholded Jaccard index (Th. Jacc.) for various experiments. Results are shown in the form of mean $\pm $ standard deviation. The top two groups show in-sample performance within the DermIS and DermQuest datasets, while the bottom two groups show out-of-sample performance when trained on DermIS and tested on DermQuest, and vice-versa.\relax }}{97}{table.245}\protected@file@percent }
\newlabel{tab:results}{{5.5}{97}{Results of our approach and the baseline model in terms of the Dice Coefficient (DSC) as well as the thresholded Jaccard index (Th. Jacc.) for various experiments. Results are shown in the form of mean $\pm $ standard deviation. The top two groups show in-sample performance within the DermIS and DermQuest datasets, while the bottom two groups show out-of-sample performance when trained on DermIS and tested on DermQuest, and vice-versa.\relax }{table.245}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces A box plot of Jaccard indices above or equal to 0.65 (above) and the number of Jaccard indices below 0.65 (below). The first two columns show in-sample results, while the last two columns show out-of-sample results for models trained on DermIS and tested on DermQuest and vice-versa.\relax }}{98}{figure.caption.246}\protected@file@percent }
\newlabel{fig:box-plot}{{5.10}{98}{A box plot of Jaccard indices above or equal to 0.65 (above) and the number of Jaccard indices below 0.65 (below). The first two columns show in-sample results, while the last two columns show out-of-sample results for models trained on DermIS and tested on DermQuest and vice-versa.\relax }{figure.caption.246}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Conclusion}{99}{section.247}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Will cite the paper when it is published.}{99}{section*.248}\protected@file@percent }
\@setckpt{Chapters/05_input_size_reduction}{
\setcounter{page}{100}
\setcounter{equation}{4}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{5}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{@todonotes@numberoftodonotes}{2}
\setcounter{parentequation}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{4}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{float@type}{16}
\setcounter{algorithm}{1}
\setcounter{ALG@line}{27}
\setcounter{ALG@rem}{27}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{361}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{5}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{7}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{4}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{5}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{1}
\setcounter{textcitetotal}{1}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{26}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{65}
\setcounter{lstnumber}{1}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
\setcounter{blx@maxsegment@1}{0}
\setcounter{blx@sectionciteorder@1}{49}
\setcounter{blx@maxsegment@2}{0}
\setcounter{blx@sectionciteorder@2}{97}
\setcounter{blx@maxsegment@3}{0}
\setcounter{blx@sectionciteorder@3}{49}
\setcounter{blx@maxsegment@4}{0}
\setcounter{blx@sectionciteorder@4}{113}
\setcounter{blx@maxsegment@5}{0}
\setcounter{blx@sectionciteorder@5}{42}
}
