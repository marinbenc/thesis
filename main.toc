\babel@toc {english}{}\relax 
\contentsline {chapter}{Abstract}{III}{section*.1}%
\contentsline {chapter}{Acknowledgements}{IV}{section*.2}%
\contentsline {chapter}{List of Figures}{VII}{chapter*.4}%
\contentsline {chapter}{List of Tables}{XIII}{chapter*.5}%
\contentsline {chapter}{List of Abbreviations}{XV}{chapter*.6}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.7}%
\contentsline {section}{\numberline {1.1}Contributions}{2}{section.8}%
\contentsline {subsubsection}{A new biomedical image segmentation method based on polar transform preprocessing with a learned center point.}{2}{section*.9}%
\contentsline {subsubsection}{An improved method of reducing input image size in neural networks using salient image crops.}{2}{section*.10}%
\contentsline {subsubsection}{A new neural network architecture for high-resolution image segmentation that combines object detection in low-resolution images and segmentation in high-resolution images.}{3}{section*.11}%
\contentsline {subsubsection}{A new method of embedding depth information in two-dimensional convolutional neural network input data.}{3}{section*.13}%
\contentsline {section}{\numberline {1.2}Organization of the thesis}{3}{section.14}%
\contentsline {chapter}{\numberline {2}Neural Network-Based Segmentation of Biomedical Images}{4}{chapter.16}%
\contentsline {section}{\numberline {2.1}Common Types of Biomedical Images}{4}{section.17}%
\contentsline {subsection}{\numberline {2.1.1}3D Modalities}{4}{subsection.18}%
\contentsline {subsubsection}{Computed Tomography (CT)}{5}{section*.19}%
\contentsline {subsubsection}{Magnetic Resonance Imaging (MRI)}{7}{section*.24}%
\contentsline {subsection}{\numberline {2.1.2}2D Modalities}{8}{subsection.29}%
\contentsline {subsubsection}{X-ray imaging}{8}{section*.30}%
\contentsline {subsubsection}{Dermatological images (clinical and dermatoscopic)}{9}{section*.31}%
\contentsline {subsubsection}{Microscopy}{9}{section*.32}%
\contentsline {section}{\numberline {2.2}Image Segmentation: From Images to Segmentation Maps}{9}{section.33}%
\contentsline {subsection}{\numberline {2.2.1}Traditional Image Processing Methods}{10}{subsection.35}%
\contentsline {subsubsection}{Image Thresholding}{11}{section*.36}%
\contentsline {subsubsection}{Region Growing Techniques}{11}{section*.37}%
\contentsline {subsubsection}{Active Contours or Snakes}{12}{section*.39}%
\contentsline {subsubsection}{Atlas-Based Segmentation}{12}{section*.41}%
\contentsline {subsection}{\numberline {2.2.2}Machine Learning}{13}{subsection.43}%
\contentsline {section}{\numberline {2.3}Deep Learning-Based Segmentation Methods}{14}{section.46}%
\contentsline {subsection}{\numberline {2.3.1}Neural Network Training, Validation and Testing}{15}{subsection.51}%
\contentsline {subsection}{\numberline {2.3.2}Encoders and Decoders}{16}{subsection.52}%
\contentsline {subsection}{\numberline {2.3.3}Convolutional Neural Networks}{17}{subsection.54}%
\contentsline {subsubsection}{Convolution}{17}{section*.55}%
\contentsline {subsubsection}{Convolutional Layers}{19}{section*.60}%
\contentsline {subsubsection}{Pooling Layers}{20}{section*.62}%
\contentsline {section}{\numberline {2.4}CNN Architectures for Medical Image Segmentation}{21}{section.64}%
\contentsline {subsection}{\numberline {2.4.1}Fully Convolutional Network (FCN)}{22}{subsection.65}%
\contentsline {subsection}{\numberline {2.4.2}U-Net and Its Variants}{22}{subsection.67}%
\contentsline {subsubsection}{nnU-Net}{23}{section*.69}%
\contentsline {subsubsection}{U-Net++}{24}{section*.71}%
\contentsline {subsection}{\numberline {2.4.3}Mask R-CNN}{25}{subsection.73}%
\contentsline {subsection}{\numberline {2.4.4}Other Notable Segmentation CNNs}{26}{subsection.75}%
\contentsline {section}{\numberline {2.5}Fully Connected Transformers for Medical Image Segmentation}{27}{section.76}%
\contentsline {subsection}{\numberline {2.5.1}Attention}{27}{subsection.77}%
\contentsline {subsection}{\numberline {2.5.2}Positional Encoding}{29}{subsection.83}%
\contentsline {subsection}{\numberline {2.5.3}Adapting Transformers to Image Segmentation}{29}{subsection.85}%
\contentsline {chapter}{\numberline {3}Data Efficiency in Neural Network-Based Image Segmentation}{31}{chapter.87}%
\contentsline {section}{\numberline {3.1}Transfer Learning}{34}{section.98}%
\contentsline {subsection}{\numberline {3.1.1}Simple Transfer Learning}{34}{subsection.99}%
\contentsline {subsection}{\numberline {3.1.2}Domain Adaptation}{35}{subsection.101}%
\contentsline {subsection}{\numberline {3.1.3}Semi-Supervised and Self-Supervised Learning}{36}{subsection.103}%
\contentsline {section}{\numberline {3.2}Synthetic Data}{37}{section.105}%
\contentsline {section}{\numberline {3.3}Regularization}{37}{section.106}%
\contentsline {section}{\numberline {3.4}Conclusion}{38}{section.109}%
\contentsline {chapter}{\numberline {4}Data Efficiency via Model-Driven Preprocessing}{39}{chapter.110}%
\contentsline {section}{\numberline {4.1}Motivation: Using The Polar Transform for Preprocessing}{39}{section.111}%
\contentsline {section}{\numberline {4.2}Model-driven Preprocessing}{41}{section.117}%
\contentsline {subsection}{\numberline {4.2.1}Training Model-Driven Preprocessing Networks}{43}{subsection.122}%
\contentsline {subsubsection}{Training the Transformation Parameter Predictor}{43}{section*.123}%
\contentsline {subsubsection}{Training the Segmentation Network}{44}{section*.125}%
\contentsline {subsubsection}{Transfer Learning}{44}{section*.127}%
\contentsline {section}{\numberline {4.3}Model-Driven Polar Transform Using Centerpoint Prediction}{45}{section.131}%
\contentsline {subsection}{\numberline {4.3.1}Background and Related Work}{45}{subsection.132}%
\contentsline {subsubsection}{Previous work using the polar transform for medical image processing}{46}{section*.135}%
\contentsline {subsection}{\numberline {4.3.2}Methodology}{47}{subsection.136}%
\contentsline {subsection}{\numberline {4.3.3}Centerpoint prediction}{47}{subsection.139}%
\contentsline {subsubsection}{(A) Training the same neural network on cartesian and polar images}{48}{section*.140}%
\contentsline {subsubsection}{(B) Training a centerpoint predictor}{48}{section*.142}%
\contentsline {subsection}{\numberline {4.3.4}Experiments}{50}{subsection.145}%
\contentsline {subsubsection}{Datasets description}{50}{section*.150}%
\contentsline {subsubsection}{Implementation details}{52}{section*.156}%
\contentsline {subsection}{\numberline {4.3.5}Results and Discussion}{52}{subsection.158}%
\contentsline {subsubsection}{Discussion}{57}{section*.165}%
\contentsline {section}{\numberline {4.4}Supporting Multiple Transformations of an Image}{59}{section.172}%
\contentsline {section}{\numberline {4.5}Model-Driven Preprocessing using Multiple Transformations for Aorta Segmentation}{61}{section.179}%
\contentsline {subsection}{\numberline {4.5.1}Methodology}{62}{subsection.180}%
\contentsline {subsubsection}{Data Description and Preprocessing}{63}{section*.183}%
\contentsline {subsection}{\numberline {4.5.2}Results and Discussion}{63}{subsection.184}%
\contentsline {section}{\numberline {4.6}Conclusion}{64}{section.189}%
\contentsline {chapter}{\numberline {5}Reducing Model Input Sizes with Model-Driven Crops}{68}{chapter.190}%
\contentsline {section}{\numberline {5.1}Model-Driven Image Cropping}{69}{section.193}%
\contentsline {subsubsection}{Cropping}{70}{section*.198}%
\contentsline {subsubsection}{Fine Segmentation and Fusion}{72}{section*.199}%
\contentsline {subsubsection}{Training the Fine Segmentation Network}{72}{section*.200}%
\contentsline {subsection}{\numberline {5.1.1}Related work}{72}{subsection.201}%
\contentsline {subsubsection}{Detect-then-segment}{72}{section*.202}%
\contentsline {subsubsection}{Coarse-to-fine Segmentation}{73}{section*.203}%
\contentsline {subsubsection}{Non-uniform Downsampling}{73}{section*.204}%
\contentsline {subsubsection}{Other Approaches to Reducing Input Resolution}{74}{section*.205}%
\contentsline {subsection}{\numberline {5.1.2}Results}{74}{subsection.206}%
\contentsline {subsubsection}{Datasets}{75}{section*.208}%
\contentsline {subsubsection}{Quantitative Assessment}{75}{section*.209}%
\contentsline {subsubsection}{Qualitative Assessment}{78}{section*.214}%
\contentsline {subsubsection}{Computational Performance Characteristics}{81}{section*.218}%
\contentsline {subsection}{\numberline {5.1.3}Discussion}{82}{subsection.221}%
\contentsline {section}{\numberline {5.2}An End-to-End Extension of Model-Driven Image Cropping}{83}{section.222}%
\contentsline {subsection}{\numberline {5.2.1}End-to-end Network Architecture and Training}{83}{subsection.223}%
\contentsline {subsection}{\numberline {5.2.2}Experiments in Clinical Dermatological Image Segmentation}{84}{subsection.225}%
\contentsline {subsubsection}{Results and Discussion}{84}{section*.226}%
\contentsline {section}{\numberline {5.3}Conclusion}{89}{section.230}%
\contentsline {chapter}{\numberline {6}Adding Depth Information to 2D U-Nets for CT Segmentation}{90}{chapter.232}%
\contentsline {section}{\numberline {6.1}Epicardial Adipose Tissue Segmentation}{91}{section.234}%
\contentsline {section}{\numberline {6.2}Related Work}{91}{section.235}%
\contentsline {section}{\numberline {6.3}Dataset Description}{92}{section.236}%
\contentsline {section}{\numberline {6.4}Methodology}{93}{section.238}%
\contentsline {subsection}{\numberline {6.4.1}Data Preprocessing}{93}{subsection.241}%
\contentsline {subsection}{\numberline {6.4.2}Model Training}{94}{subsection.243}%
\contentsline {section}{\numberline {6.5}Experiments and Results}{94}{section.244}%
\contentsline {subsection}{\numberline {6.5.1}Results}{95}{subsection.245}%
\contentsline {section}{\numberline {6.6}Conclusion}{97}{section.250}%
