\chapter{Conclusion}
\label{chap:conclusion}

Recent advances in neural network-based image segmentation have largely been achieved by leveraging very large datasets to train high-capacity neural networks. There has been comparatively less research in improving performance using small neural networks on datasets with few samples. Rather than relying on foundation models that offer good initial segmentation on unseen datasets but lack the precision necessary for medical purposes, our work emphasizes the importance of domain-specific knowledge to develop smaller, more precise networks tailored to specific medical imaging tasks. These networks are not only more suitable for medical applications but also more manageable for fine-tuning and evaluation on standard computing hardware due to their reduced complexity.

Our methodology integrates traditional image processing techniques with neural networks to simplify the segmentation process. We employ small neural networks for initial object localization. Using hand-crafted functions, optimal image transformation parameters are estimated from the initial segmentation. The image transformations themselves are chosen to be beneficial for the specific task based on domain knowledge from both medicine and image processing. As a result, downstream neural networks trained on the transformed images require fewer parameters for effective segmentation, enhancing their data efficiency.

We have investigated this approach in a wide variety of contexts in medical imaging. Initially, we focused on the polar transform to simplify the segmentation boundary of elliptical shapes commonly seen in organs, vessels, and skin lesions. By employing a neural network to determine the optimal origin for the polar transform, we enhanced segmentation accuracy in CT scans, colonoscopies, and dermatoscopic images, achieving state-of-the-art results for lesion and polyp segmentation. We also showed that we can reduce the sample size and still achieve good segmentation performance.

Furthermore, we have evaluated image cropping both for improving segmentation as well as reducing image input sizes in segmentation convolutional neural networks. By cropping a high-resolution image to a region of interest predicted by a neural network, we can segment only the relevant portion of the image, maintaining fine details while reducing the total input size. Since convolutional neural network complexity grows with image input size, this approach can improve data efficiency by reducing model complexity. This concept was further developed into a unified end-to-end trainable model, improving the robustness of both the initial localization and detailed segmentation processes.

Our approach offers a versatile framework for enhancing data efficiency in medical image segmentation, opening up numerous avenues for future research to refine and expand these methods. One promising direction is to reformulate the image transformations we've employed into differentiable functions, allowing them to be integrated into the neural network. This would enable the network to learn image features beneficial for estimating the transformation parameters, potentially improving the results.

Additionally, there is significant potential in leveraging unlabeled data to improve the data efficiency of our approach. Given that the estimation of image transformation parameters depends only on a rough localization of the target object, there is a reduced need for precise segmentation labels for this stage. This opens up the possibility of training the localization network with weaker forms of annotations, such as bounding boxes or heatmaps derived from neuron activations, which are less granular than segmentation masks but can still provide valuable spatial information about the object's location.

Furthermore, the reliance on hand-crafted functions to estimate transformation parameters based on object localization could be eliminated by employing a neural network to directly predict the optimal parameters for transformation. We have already taken steps in this direction by treating center point prediction as a Gaussian image prediction task. One could go further and use regression neural networks to achieve similar results. However, a regression-based approach might present challenges, as models regressing values from images tend to converge more slowly compared to image-to-image models, such as those used in segmentation tasks. Thus, careful consideration of loss functions would be needed.

Finally, one could fully remove any explicit transformation selection from the approach, and instead use a general deformation field as the transformation. The neural network would generate the values for this deformation field, akin to techniques used in image registration tasks. This would allow the network to automatically discover beneficial transformations or be guided to learn them by training with manually transformed versions of the input image as targets. This approach could potentially improve adaptability and data efficiency in medical image segmentation by allowing the network's capacity to learn and apply optimal transformations for each specific segmentation task and image.

All of these proposed improvements as well as the approaches described in this thesis represent different points on the spectrum of model complexity. As suggested by statistical learning theory, there's an inherent tradeoff between a model's bias and its variance. By explicitly incorporating domain knowledge into the model, we improve its data efficiency but limit its ability to model complex functions. Our approach facilitates a more nuanced management of this balance, offering a level of flexibility and precision that more traditional neural network-based segmentation strategies may not provide. Calibrating the balance between bias and variance is a fundamental decision when creating reliable medical image segmentation models, particularly when working with limited datasets. We hope that this work inspires further future research in ways to embed domain knowledge to simplify segmentation neural networks, as we believe such an approach is necessary in the field of medical imaging to achieve reliable segmentation when faced with small sample sizes.
